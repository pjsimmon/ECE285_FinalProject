{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brFxWte7yM-X"
   },
   "source": [
    "# **Clone the PyTorch I3D model**\n",
    "https://github.com/piergiaj/pytorch-i3d.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17936,
     "status": "ok",
     "timestamp": 1591063726172,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "I1ePO34Ax-te",
    "outputId": "d8a5743b-7db9-4b2a-eb96-05a0e6bbf6e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/piergiaj/pytorch-i3d.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4245,
     "status": "ok",
     "timestamp": 1591135131315,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "ptPILytYyFqc",
    "outputId": "f6981d94-fc65-49af-b3e9-f6a9e60f8560",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pjsimmon/ECE285_Final_Dataset/drive-pytorch-i3d\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kinect_ir_train_list = \"kinect_ir_processed_list_rgb_split0train.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqzWvG8i0THH"
   },
   "source": [
    "# **Test Functionality of PyTorch I3D model**\n",
    "\n",
    "### Starting with charades_dataset.py:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avmOWept0SSj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data_utl\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-p8HYk8y5JN"
   },
   "outputs": [],
   "source": [
    "# Testing getting a tensor from one of our .npy files:\n",
    "def video_to_tensor(pic):\n",
    "    \"\"\"Convert a ``numpy.ndarray`` to tensor.\n",
    "    Converts a numpy.ndarray (T x H x W x C)\n",
    "    to a torch.FloatTensor of shape (C x T x H x W)\n",
    "    \n",
    "    Args:\n",
    "         pic (numpy.ndarray): Video to be converted to tensor.\n",
    "    Returns:\n",
    "         Tensor: Converted video.\n",
    "    \"\"\"\n",
    "    return torch.from_numpy(pic.transpose([3,0,1,2]))\n",
    "    #return torch.from_numpy(pic.transpose([0, 4, 1, 2, 3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1591132487368,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "9y_Oiu7w14Ja",
    "outputId": "39db90d8-2d20-42d9-85b9-e3a870685c1e"
   },
   "source": [
    "## Updated with new path to kinect_ir .npy files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16411,
     "status": "ok",
     "timestamp": 1591135170778,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "BKIEx0Kd16m9",
    "outputId": "78d3fced-7348-4652-8633-f6eec0d9baf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Old path to .npy files\n",
    "root = \"../../ece285_sp20_team01/kinect_ir/output/\"\n",
    "path_to_npy_files = root + \"video_npy/\"\n",
    "path_to_train_list = root + new_kinect_ir_train_list\n",
    "path_to_test_npy = \"../../ece285_sp20_team01/kinect_ir/output/video_npy/run1_2018-05-03-14-08-31.kinect_ir.mp4_000500_000557.npy\"\n",
    "\n",
    "print(os.path.exists(path_to_npy_files))\n",
    "print(os.path.exists(path_to_train_list))\n",
    "print(os.path.exists(path_to_test_npy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfS3UKxI2_Kl"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../../ece285_sp20_team01/kinect_ir/output/video_npy/run1_2018-05-03-14-08-31.kinect_ir.mp4_000500_000557.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-96d93a5ee754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_test_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_npy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../../ece285_sp20_team01/kinect_ir/output/video_npy/run1_2018-05-03-14-08-31.kinect_ir.mp4_000500_000557.npy'"
     ]
    }
   ],
   "source": [
    "test_npy = np.load(path_to_test_npy)\n",
    "print(test_npy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0YLe7YK5Xge"
   },
   "source": [
    "## Adapt make_dataset and charades_dataset to our dataset, Drive&Act:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPR6pEe47gmJ"
   },
   "outputs": [],
   "source": [
    "# Adaptation of make_dataset to use out train_list rather than a .json file: \n",
    "\n",
    "# Replace charades_dataset.py with this: \n",
    "def make_our_dataset(train_list):\n",
    "    dataset = []\n",
    "    with open(train_list, 'r') as f: \n",
    "        Lines = f.readlines()\n",
    "        for line in Lines: \n",
    "            line = line.strip()\n",
    "            if (len(line) > 0):\n",
    "                contents = line.split(\" \")\n",
    "                \n",
    "                vid_path = contents[0]\n",
    "                activity = contents[1]\n",
    "                \n",
    "                # get number of frames from name of vid_path\n",
    "                # (using new ir list): \n",
    "\n",
    "                start_str = \".mp4_\"\n",
    "                end_str = \" \"\n",
    "\n",
    "                num_frames = (vid_path.split(start_str))[1].split(end_str)[0]\n",
    "                start_frame = int(num_frames.split(\"_\")[0])\n",
    "                end_frame = int(num_frames.split(\"_\")[1])                \n",
    "\n",
    "                num_frames = end_frame - start_frame\n",
    "                \n",
    "                \n",
    "                if int(num_frames) < 64: \n",
    "                    continue\n",
    "                    \n",
    "                dataset.append((vid_path, activity, num_frames))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = make_our_dataset(path_to_train_list)\n",
    "print(len(train_data))\n",
    "\n",
    "for row in train_data[0:5]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to balance the training class samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(train_data):\n",
    "\n",
    "    len_data = len(train_data)\n",
    "    num_labels = 39\n",
    "\n",
    "    sample_labels = np.zeros(num_labels)\n",
    "\n",
    "    for row in train_data: \n",
    "        label = row[1]\n",
    "        sample_labels[int(label)] += 1\n",
    "\n",
    "    return sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make sure each activity appears at least once in the training set: \n",
    "\n",
    "train_sampled_data = sample_data(train_data)\n",
    "#val_sampled_data = sample_data(val_data)\n",
    "\n",
    "print(train_sampled_data)\n",
    "#print(train_sampled_data + val_sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create a *representative* training set.\n",
    "import random\n",
    "\n",
    "all_data = train_data\n",
    "num_classes = 39\n",
    "data_dict = {}\n",
    "\n",
    "train_data_sample = []\n",
    "val_data_sample = []\n",
    "test_data_sample = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    data_dict[i] = 0\n",
    "\n",
    "# the train/val/test split will be 65/25/10\n",
    "for row in all_data: \n",
    "    activity = int(row[1])\n",
    "    if data_dict[activity] < 0.65*train_sampled_data[activity]:\n",
    "        train_data_sample.append(row)\n",
    "        data_dict[activity] += 1\n",
    "    else: \n",
    "        prob = random.random()\n",
    "        if prob < float(25/35): \n",
    "            #random 25/35 chance of going into validation: \n",
    "            val_data_sample.append(row)\n",
    "        else:\n",
    "            #random 10/35 chance of going into test:\n",
    "            test_data_sample.append(row)\n",
    "\n",
    "print(len(train_data_sample))\n",
    "print(len(val_data_sample))\n",
    "print(len(test_data_sample))\n",
    "\n",
    "#print(train_data_sample)\n",
    "\n",
    "train_list_sampled_data = sample_data(train_data_sample)\n",
    "val_list_sampled_data = sample_data(val_data_sample)\n",
    "test_list_sampled_data = sample_data(test_data_sample)\n",
    "\n",
    "print(train_list_sampled_data)\n",
    "print(val_list_sampled_data)\n",
    "print(test_list_sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train, val, test list from each of the sampled datas: \n",
    "\n",
    "'''\n",
    "def write_data_to_list(filename, data_list):\n",
    "    with open(filename, 'w') as f: \n",
    "        for row in data_list: \n",
    "            f.write(row[0] + \" \" + row[1])\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "write_data_to_list(\"new_kinect_ir_train.txt\", train_data_sample)\n",
    "write_data_to_list(\"new_kinect_ir_val.txt\", val_data_sample)\n",
    "write_data_to_list(\"new_kinect_ir_test.txt\", test_data_sample)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code to create the WeightedRandomSampler\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "numDataPoints = 1000\n",
    "data_dim = 5\n",
    "bs = 100\n",
    "\n",
    "# Create dummy data with class imbalance 9 to 1\n",
    "data = torch.FloatTensor(numDataPoints, data_dim)\n",
    "target = np.hstack((np.zeros(int(numDataPoints * 0.9), dtype=np.int32),\n",
    "                    np.ones(int(numDataPoints * 0.1), dtype=np.int32)))\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "print(class_sample_count)\n",
    "print(weight)\n",
    "print(samples_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic: we will upsample the small classes and downsample the large classes.\n",
    "# The classes that are 0 we never see in our train or test sets.\n",
    "\n",
    "# Link to sampler code: https://discuss.pytorch.org/t/how-to-handle-imbalanced-classes/11264/2\n",
    "\n",
    "def training_sampler(train_list):\n",
    "    train_sampled_data = sample_data(train_list)\n",
    "    train_weight = []\n",
    "    \n",
    "    for v in train_sampled_data: \n",
    "        if v == 0: \n",
    "            train_weight.append(0)\n",
    "        else:\n",
    "            train_weight.append(1. / v)\n",
    "\n",
    "    # Create the weight samples for the WeightedRanomSampler\n",
    "    samples_weight = []\n",
    "    for row in train_list: \n",
    "        activity = int(row[1])\n",
    "        samples_weight.append(train_weight[activity])\n",
    "        \n",
    "    samples_weight = torch.from_numpy(np.array(samples_weight))\n",
    "    samples_weight = samples_weight.double()\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    \n",
    "    return train_weight, samples_weight, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights, train_samples_weights, train_sampler = training_sampler(train_data_sample)\n",
    "print(train_weights)\n",
    "print()\n",
    "print(len(train_samples_weights), len(train_data_sample))\n",
    "print(train_samples_weights)\n",
    "print()\n",
    "print(train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 64 frames from the passed in npy file. \n",
    "\n",
    "def random64frames(npy_file):\n",
    "    img_array = np.load(npy_file)\n",
    "    \n",
    "    print(\"shape: \", img_array.shape)\n",
    "    \n",
    "    num_frames = img_array.shape[0] / 224.0 \n",
    "    if mode == 'ir':\n",
    "        num_channels = 1\n",
    "    \n",
    "    img_array = img_array.reshape(int(num_frames), 224, 224, 1)\n",
    "    print(img_array.shape)\n",
    "    \n",
    "    choices = num_frames - 64\n",
    "    \n",
    "    rand_start = random.randint(0, choices)\n",
    "    print(rand_start)\n",
    "    img_array = img_array[rand_start:rand_start+64, :, :, :]\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6S41yBs5cOe"
   },
   "outputs": [],
   "source": [
    "class DriveAndAct(data_utl.Dataset):\n",
    "\n",
    "    def __init__(self, train_list, mode, root, transforms=None):\n",
    "        \n",
    "        self.data = make_our_dataset(train_list)\n",
    "        self.mode = mode # FLOW, RGB, gray\n",
    "        self.root = root # root_dir that points to mode .npy files\n",
    "        self.transforms = transforms # which transforms to perform \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        vid, label, nf = self.data[index]\n",
    "\n",
    "        # imgs should be a .npy array with the correct dimensions\n",
    "        if self.mode == 'rgb':\n",
    "            # TO DO: change to rgb dir\n",
    "            print(\"TO DO: change to rgb dir\")\n",
    "            # gray_path = \"data/drive_and_act_dataset/simmons_kinect_ir_train/\"\n",
    "            # imgs = np.load(gray_path + self.data[index][0])\n",
    "            channels = 3\n",
    "        elif self.mode == 'flow':\n",
    "            # TO DO: change to flow dir\n",
    "            print(\"TO DO: change to flow dir\")\n",
    "            # gray_path = \"data/drive_and_act_dataset/simmons_kinect_ir_train/\"\n",
    "            # imgs = np.load(gray_path + self.data[index][0])\n",
    "            channels = 2\n",
    "        elif self.mode == 'ir': \n",
    "            # new list: \n",
    "            gray_path = \"../../ece285_sp20_team01/kinect_ir/output/\"\n",
    "            imgs = np.load(gray_path + self.data[index][0] + '.npy')\n",
    "            imgs = imgs.astype(np.float32)\n",
    "            imgs = (imgs/255.)*2-1 # normalization\n",
    "            channels = 1\n",
    "        elif self.mode == 'depth': \n",
    "            gray_path = \"/home/yuj010/ECE285/output/\"\n",
    "            imgs = np.load(gray_path + self.data[index][0] + '.npy')\n",
    "            imgs = imgs.astype(np.float32)\n",
    "            imgs = (imgs/255.)*2-1 # normalization\n",
    "            channels = 3\n",
    "        else: \n",
    "            print(\"did not specify correct mode for data\")\n",
    "\n",
    "        label = self.data[index][1]\n",
    "        \n",
    "        # Randomly select 64 frames:\n",
    "        num_frames = int(imgs.shape[0])\n",
    "        choices = int(num_frames) - 64\n",
    "        if choices <= 0: \n",
    "            rand_start = 0\n",
    "        else: \n",
    "            rand_start = random.randint(0, choices)\n",
    "        img_array = imgs[rand_start:rand_start+64, :, :, :]\n",
    "        \n",
    "        num_classes = 39\n",
    "\n",
    "        imgs = np.asarray(img_array, dtype='float32' )\n",
    "\n",
    "        if channels == 1: \n",
    "            imgs = np.repeat(img_array, 3, axis=3)\n",
    "\n",
    "        label = int(label)\n",
    "        labels = np.zeros((num_classes,), np.float32)\n",
    "        labels[int(label)] = 1\n",
    "        \n",
    "        return video_to_tensor(imgs), torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvdT6B6lIFPe"
   },
   "source": [
    "## **Test functionality of make_our_dataset and DriveAndAct dataset class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1591072175796,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "zE_E045AQqSW",
    "outputId": "3626d0ec-522e-4ee5-ba66-5c3c0d44d717"
   },
   "outputs": [],
   "source": [
    "# Create two sample lists: train_list and eval_list: (already done in google drive)\n",
    "'''\n",
    "import random\n",
    "len_ir_dataset = len(drive_data)\n",
    "\n",
    "original_list = \"../drive-pytorch-i3kinect_ir_processed_list_split0train.txt\"\n",
    "with open(original_list, 'r') as f1: \n",
    "    with open('../sample_train_list.txt', 'w') as f2: \n",
    "        with open('../sample_val_list.txt', 'w') as f3:\n",
    "            with open('../sample_test_list.txt', 'w') as f4:\n",
    "                Lines = f1.readlines()\n",
    "                random.shuffle(Lines)\n",
    "                for i,line in enumerate(Lines):\n",
    "                    if i < int(len_ir_dataset * (4 / 5)):\n",
    "                        f2.write(line) \n",
    "                    else:\n",
    "                        f3.write(line)\n",
    "\n",
    "!cat ../output/sample_test_list.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = \"new_kinect_ir_train.txt\"\n",
    "val_list = \"new_kinect_ir_val.txt\"\n",
    "test_list = \"new_kinect_ir_test.txt\"\n",
    "\n",
    "print(os.path.exists(train_list))\n",
    "print(os.path.exists(val_list))\n",
    "print(os.path.exists(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jb3MrUj45eBj"
   },
   "outputs": [],
   "source": [
    "# Need to be in pytorch-i3d directory\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This is the I3D model used by the Drive&Act paper\n",
    "from i3dpt import I3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5330,
     "status": "ok",
     "timestamp": 1591137775342,
     "user": {
      "displayName": "Purisa Jasmine Simmons",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeykJHL0yeviJU3DdAHufBsT-LHPwf8PfZvmIUxA=s64",
      "userId": "03888111818633929500"
     },
     "user_tz": 420
    },
    "id": "0zl7aTJmM48r",
    "outputId": "602dfdd9-0a8d-4bab-87a8-43d1e87df444"
   },
   "outputs": [],
   "source": [
    "model_rgb_path = \"model_rgb.pth\"\n",
    "model_flow_path = \"model_flow.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_wF5-YrcJ938",
    "outputId": "45083200-ffda-4c08-9d16-ddc5cf43624d"
   },
   "outputs": [],
   "source": [
    "# Need to be in pytorch-i3d directory\n",
    "\n",
    "# Choose a mode: 'ir', 'depth', 'rgb', 'flow'. \n",
    "\n",
    "# Change batch size equal to 1. \n",
    "def drive_run(init_lr=0.01, max_steps=150, train_loss = [], val_loss = [], mode='ir', root=\"\", batch_size=1, save_model='', weighted_sampler=None):\n",
    "    \n",
    "    root_path = \"\"\n",
    "    train_list = \"new_kinect_ir_train.txt\"\n",
    "    val_list = \"new_kinect_ir_val.txt\"\n",
    "\n",
    "    train_transforms = None\n",
    "    test_transforms = None\n",
    "\n",
    "    # create a dataset from our DriveAndAct dataset: \n",
    "    # !ls\n",
    "    train_dataset = DriveAndAct(train_list, mode, root=root_path, transforms=None)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True, sampler=weighted_sampler)\n",
    "\n",
    "    val_dataset = DriveAndAct(val_list, mode, root=root_path, transforms=None)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True, sampler=None)\n",
    "\n",
    "    dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "    datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "\n",
    "    \n",
    "    # setup the model\n",
    "    if mode == 'ir':\n",
    "        i3d = I3D(400, modality = 'rgb')\n",
    "        i3d.load_state_dict(torch.load('model_rgb.pth'))\n",
    "    num_classes = 39\n",
    "    i3d.replace_logits(num_classes)\n",
    "\n",
    "\n",
    "    i3d.cuda()\n",
    "    i3d = nn.DataParallel(i3d)\n",
    "\n",
    "    lr = init_lr\n",
    "    optimizer = optim.SGD(i3d.parameters(), lr=lr, momentum=0.9, weight_decay=0.0000001)\n",
    "    lr_sched = optim.lr_scheduler.MultiStepLR(optimizer, [300, 1000])\n",
    "\n",
    "\n",
    "    num_steps_per_update = 8 # accumulating gradients (\"virtual\" batch size)\n",
    "    steps = 0\n",
    "\n",
    "    # train it\n",
    "    while steps < max_steps: #for epoch in range(num_epochs):\n",
    "        print('Step {}/{}'.format(steps, max_steps))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                i3d.train() # Set model to train mode\n",
    "            else:\n",
    "                i3d.eval()  # Set model to evaluate mode\n",
    "                \n",
    "            tot_loss = 0.0\n",
    "            tot_loc_loss = 0.0\n",
    "            tot_cls_loss = 0.0\n",
    "            num_iter = 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                num_iter += 1\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                #t = inputs.size(2)\n",
    "                labels = Variable(labels.cuda())\n",
    "                \n",
    "                # Size of out is: B x C\n",
    "                out, per_frame_logits = i3d(inputs)\n",
    "                \n",
    "                \n",
    "                #print(per_frame_logits.size())\n",
    "                # upsample to input size\n",
    "                #per_frame_logits = np.array(per_frame_logits, dtype = 'float')\n",
    "                #per_frame_logits = torch.from_numpy(per_frame_logits)\n",
    "                #per_frame_logits = F.upsample(per_frame_logits, t, mode='linear')\n",
    "                \n",
    "                # compute localization loss\n",
    "                #loc_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels)\n",
    "                #tot_loc_loss += loc_loss.item()\n",
    "                loc_loss = 0\n",
    "                \n",
    "                # compute classification loss (B x C)\n",
    "                cls_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels)\n",
    "                \n",
    "                #print(per_frame_logits, labels[:,:,-1])\n",
    "                #cls_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels[:,:,-1])\n",
    "                tot_cls_loss += cls_loss.item()\n",
    "\n",
    "                loss = (cls_loss)/num_steps_per_update\n",
    "                tot_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "                if num_iter == num_steps_per_update and phase == 'train':\n",
    "                    steps += 1\n",
    "                    num_iter = 0\n",
    "\n",
    "                    # weights don't update until optimizer.step() called\n",
    "                    optimizer.step()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    lr_sched.step()\n",
    "\n",
    "                    # make sure model is being saved in case we get kicked off datahub\n",
    "                    if steps % 10 == 0:\n",
    "                        print('{} Loc Loss: {:.4f} Cls Loss: {:.4f} Tot Loss: {:.4f}'.format(phase, tot_loc_loss/(10*num_steps_per_update), tot_cls_loss/(10*num_steps_per_update), tot_loss/10))\n",
    "                        # save model\n",
    "                        if steps % 20 == 0:\n",
    "                            torch.save(i3d.module.state_dict(), save_model+str(steps).zfill(6)+'.pt')\n",
    "                        train_loss.append(tot_loss/10)\n",
    "                        tot_loss = tot_loc_loss = tot_cls_loss = 0.\n",
    "                        print(\"Model saved: \", save_model+str(steps).zfill(6)+'.pt')\n",
    "                        \n",
    "                    \n",
    "                if phase == 'val':\n",
    "                    print('{} Loc Loss: {:.4f} Cls Loss: {:.4f} Tot Loss: {:.4f}'.format(phase, tot_loc_loss/num_iter, tot_cls_loss/num_iter, (tot_loss*num_steps_per_update)/num_iter))\n",
    "                    val_loss.append((tot_loss*num_steps_per_update)/num_iter)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    drive_run(train_loss = t_loss, val_loss = v_loss, weighted_sampler=train_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(t_loss)\n",
    "#print(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4U29zEPIbAb"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(t_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('10 epoch')\n",
    "plt.legend(['Train Loss'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(v_loss)\n",
    "plt.title('Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Validation Phase')\n",
    "plt.legend(['Val loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Smooth out the losses in training and validation: \n",
    "window = 5\n",
    "\n",
    "new_t_loss = []\n",
    "new_v_loss = []\n",
    "\n",
    "for i in range(0,window):\n",
    "    new_t_loss.append(t_loss[i])\n",
    "    new_v_loss.append(v_loss[i])\n",
    "\n",
    "for i in range(window, len(t_loss)):\n",
    "    new_t_loss.append(sum(t_loss[i:i+window]) / window)\n",
    "    new_v_loss.append(sum(v_loss[i:i+window]) / window)\n",
    "    \n",
    "    \n",
    "#print(new_t_loss)\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(new_t_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('10 epoch')\n",
    "plt.legend(['Train Loss'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(new_v_loss)\n",
    "plt.title('Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Validation Phase')\n",
    "plt.legend(['Val loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Make a new notebook for the testing code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OiaZy7jaMi7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test(mode='ir', batch_size=1, accuracy_per_frame = False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    test_transforms=None\n",
    "    \n",
    "    root_path = \"\"\n",
    "    train_list = \"new_kinect_ir_train.txt\"\n",
    "    val_list = \"new_kinect_ir_val.txt\"\n",
    "    test_list = \"new_kinect_ir_test.txt\"\n",
    "    \n",
    "    val_list = test_list\n",
    "\n",
    "    train_dataset = DriveAndAct(train_list, mode=mode, root='', transforms=test_transforms)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    val_dataset = DriveAndAct(val_list, mode=mode, root='', transforms=test_transforms)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "    dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "    datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "    \n",
    "    \n",
    "    num_classes = 39\n",
    "    \n",
    "    # setup the model\n",
    "    if mode == 'ir':\n",
    "        i3d = I3D(400, modality = 'rgb')\n",
    "        i3d.replace_logits(num_classes)\n",
    "        i3d.load_state_dict(torch.load('saved_models000420.pt'))\n",
    "    num_classes = 39\n",
    "    i3d.replace_logits(num_classes)\n",
    "    \n",
    "    i3d.cuda()\n",
    "    i3d = nn.DataParallel(i3d)\n",
    "    preds = []\n",
    "    \n",
    "    # Evaluate the model since testing\n",
    "    i3d.eval()   \n",
    "    \n",
    "    with torch.no_grad():  # Set model to evaluate mode\n",
    "\n",
    "      # Iterate over data.\n",
    "      for data in tqdm(dataloaders['val']): # modified\n",
    "          \n",
    "          # get the inputs\n",
    "          inputs, labels = data\n",
    "\n",
    "          # wrap them in Variable\n",
    "          inputs = Variable(inputs.cuda())\n",
    "          # t = inputs.size(2)\n",
    "          labels = Variable(labels.cuda())\n",
    "\n",
    "          # probs and logits are B x C\n",
    "          probs, logits = i3d(inputs)\n",
    "          # upsample to input size\n",
    "          # per_frame_logits = F.upsample(per_frame_logits, t, mode='linear')\n",
    "          \n",
    "          # compute accuracy\n",
    "          _, pred_indices = logits.max(1)    # pred_values gets probabilities, pred_indices gets output class, \n",
    "            \n",
    "          # Probability corresponding to predicted class  \n",
    "          pred_prob = probs[pred_indices]  \n",
    "            \n",
    "          actual_values, actual_indices = labels.max(1)\n",
    "          pred_indices = pred_indices.squeeze()\n",
    "          actual_indices = actual_indices.squeeze()\n",
    "\n",
    "          preds.append(pred_indices.item())\n",
    "            \n",
    "          #label = actual_indices.item()\n",
    "          #pred = pred_indices.item() \n",
    "          #print(\"prediction: \", pred, \" label: \", label)\n",
    "\n",
    "          if pred_indices == actual_indices:\n",
    "              correct += 1\n",
    "          total += 1\n",
    "               \n",
    "          \n",
    "    return correct, total, preds\n",
    "        \n",
    "    #print('{} Loc Loss: {:.4f} Cls Loss: {:.4f} Tot Loss: {:.4f}'.format(phase, tot_loc_loss/num_iter, tot_cls_loss/num_iter, (tot_loss*num_steps_per_update)/num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total, preds = test(mode='ir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(preds)\n",
    "print(Counter(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix: \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simmons_pytorch_train_i3d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
