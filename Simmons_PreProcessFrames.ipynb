{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to pre-process the .mp4 videos from the Drive&Act Dataset by extracting frames into .npy files with their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a one-hot-encoding helper function here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to modify input \"data_set\"\n",
    "def label_encoding(activity):\n",
    "    if activity == 'sitting_still':\n",
    "        activity = 0\n",
    "    elif activity == 'standing_by_the_door':\n",
    "        activity = 1\n",
    "    elif activity == 'entering_car':\n",
    "        activity = 2\n",
    "    elif activity == 'closing_door_outside':\n",
    "        activity = 3\n",
    "    elif activity == 'closing_door_inside':\n",
    "        activity = 4\n",
    "    elif activity == 'opening_laptop':\n",
    "        activity = 5\n",
    "    elif activity == 'opening_door_inside':\n",
    "        activity = 6\n",
    "    elif activity == 'fetching_an_object':\n",
    "        activity = 7\n",
    "    elif activity == 'pressing_automation_button':\n",
    "        activity = 8\n",
    "    elif activity == 'fastening_seat_belt':\n",
    "        activity = 9\n",
    "    elif activity == 'using_multimedia_display':\n",
    "        activity = 10\n",
    "    elif activity == 'closing_laptop':\n",
    "        activity = 11\n",
    "    elif activity == 'placing_an_object':\n",
    "        activity = 12\n",
    "    elif activity == 'interacting_with_phone':\n",
    "        activity = 13\n",
    "    elif activity == 'drinking':\n",
    "        activity = 14\n",
    "    elif activity == 'opening_bottle':\n",
    "        activity = 15\n",
    "    elif activity == 'eating':\n",
    "        activity = 16\n",
    "    elif activity == 'preparing_food':\n",
    "        activity = 17\n",
    "    elif activity == 'looking_back_left_shoulder':\n",
    "        activity = 18\n",
    "    elif activity == 'reading_magazine':\n",
    "        activity = 19\n",
    "    elif activity == 'talking_on_phone':\n",
    "        activity = 20\n",
    "    elif activity == 'looking_or_moving_around (e.g. searching)':\n",
    "        activity = 21\n",
    "    elif activity == 'closing_bottle':\n",
    "        activity = 22\n",
    "    elif activity == 'putting_on_jacket':\n",
    "        activity = 23\n",
    "    elif activity == 'exiting_car':\n",
    "        activity = 24\n",
    "    elif activity == 'opening_door_outside':\n",
    "        activity = 25\n",
    "    elif activity == 'writing':\n",
    "        activity = 26\n",
    "    elif activity == 'working_on_laptop':\n",
    "        activity = 27\n",
    "    elif activity == 'putting_on_sunglasses':\n",
    "        activity = 28\n",
    "    elif activity == 'taking_off_sunglasses':\n",
    "        activity = 29\n",
    "    elif activity == 'opening_backpack':\n",
    "        activity = 30\n",
    "    elif activity == 'taking_laptop_from_backpack':\n",
    "        activity = 31\n",
    "    elif activity == 'reading_newspaper':\n",
    "        activity = 32\n",
    "    elif activity == 'taking_off_jacket':\n",
    "        activity = 33\n",
    "    elif activity == 'unfastening_seat_belt':\n",
    "        activity = 34\n",
    "    elif activity == 'putting_laptop_into_backpack':\n",
    "        activity = 35\n",
    "    else:\n",
    "        print(activity)\n",
    "\n",
    "    return int(activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test getting frames from single video for single row (activity slice) from the provided .csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/activities_3s/kinect_ir/\"\n",
    "filename = \"midlevel.chunks_90.split_0.train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>activity</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>164</td>\n",
       "      <td>closing_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>260</td>\n",
       "      <td>opening_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>313</td>\n",
       "      <td>entering_car</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>5</td>\n",
       "      <td>313</td>\n",
       "      <td>348</td>\n",
       "      <td>closing_door_inside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>6</td>\n",
       "      <td>348</td>\n",
       "      <td>439</td>\n",
       "      <td>fastening_seat_belt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id                                  file_id  annotation_id  \\\n",
       "0               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              1   \n",
       "1               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              3   \n",
       "2               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              4   \n",
       "3               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              5   \n",
       "4               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              6   \n",
       "\n",
       "   frame_start  frame_end              activity  chunk_id  \n",
       "0          116        164  closing_door_outside         0  \n",
       "1          204        260  opening_door_outside         0  \n",
       "2          260        313          entering_car         0  \n",
       "3          313        348   closing_door_inside         0  \n",
       "4          348        439   fastening_seat_belt         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = pd.read_csv(path + filename)\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir/\"\n",
    "os.path.exists(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4\n",
      "116\n",
      "164\n",
      "closing_door_outside\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Test on single row \n",
    "row = 0\n",
    "video_filename = str(annotations_df[\"file_id\"][row]) + \".mp4\"        # Get video filename for each row\n",
    "\n",
    "# Extract the frames using start_frame and end_frame\n",
    "start_frame = annotations_df[\"frame_start\"][row]\n",
    "end_frame = annotations_df[\"frame_end\"][row]\n",
    "\n",
    "activity = annotations_df[\"activity\"][row]\n",
    "label = label_encoding(activity)\n",
    "\n",
    "print(video_filename)\n",
    "print(start_frame)\n",
    "print(end_frame)\n",
    "print(activity)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Code for ffmpeg: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract the video frames based on the time: \n",
    "# Assuming 30 fps \n",
    "\n",
    "\n",
    "# The following example shows how to use ffmpeg for creating a sequence of files img-001.jpeg,\n",
    "# img-002.jpeg, ..., taking one image every second from the input video:\n",
    "ffmpeg -i in.avi -vsync cfr -r 1 'img-%03d.jpeg'\n",
    "\n",
    "\n",
    "# video preprocess (should be higher dimension, but cut like this for now)\n",
    "# extracts 25 images every second and resizes them to 224x224 \n",
    "subprocess.call(\n",
    "    [\"ffmpeg\", \"-i\", root_dir + \"/video\" + video_id + \".mp4\", \"-r\", \"25\", \"-s\", \"224x224\", \"-aspect\", \"4:3\",\n",
    "     \"proc/video_process.mp4\"])\n",
    "        \n",
    "# cut videos in 10s samples\n",
    "subprocess.call([\"ffmpeg\", \"-i\", \"proc/video_process.mp4\", \"-ss\",\n",
    "                 ('%02d' % hour) + \":\" + ('%02d' % minute) + \":\" + \"00\", \"-to\",\n",
    "                 ('%02d' % next_hour) + \":\" + ('%02d' % next_min) + \":\" + \"10\",\n",
    "                 \"tmp/video_process_cropped.mp4\"])\n",
    "\n",
    "# sample the vids into 25 fps\n",
    "subprocess.call([\"ffmpeg\", \"-i\", \"tmp/video_process_cropped.mp4\", \"tmp/thumb%04d.jpg\"])\n",
    "\n",
    "# loop through all images, 25 fps for 10s\n",
    "for i in range(1, 251):\n",
    "\n",
    "    image_str = \"tmp/thumb\" + ('%04d' % i) + \".jpg\"\n",
    "    image = cv2.imread(image_str, cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapted code from previous ffmpeg code to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "video_filename = \"vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4\"\n",
    "root_dir = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir\"\n",
    "video_path = root_dir + \"/\" + video_filename\n",
    "\n",
    "proc_dir = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir\"\n",
    "subprocess.call([\"mkdir\", proc_dir + \"/proc\"])\n",
    "\n",
    "ffmpeg = \"/Users/jasminesimmons/Downloads/ffmpeg\"\n",
    "\n",
    "# Extracts 30 images every second from video and resizes images to 224x224 with aspect ratio 4:3\n",
    "subprocess.call([ffmpeg, \"-i\", video_path, \"-r\", \"30\", \"-s\", \"224x224\", \"-aspect\", \"4:3\", \"proc/video_process.mp4\"])\n",
    "\n",
    "# Extracts 1 image every second from video and resizes images to 224x224 with aspect ratio 4:3\n",
    "# subprocess.call([ffmpeg, \"-i\", video_path, \"-r\", \"1\", \"-s\", \"224x224\", \"-aspect\", \"4:3\", proc_dir + \"/proc/video_process.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(proc_dir + \"/proc/video_process.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "3.8666666666666667\n",
      "5.466666666666667\n",
      "1.6\n"
     ]
    }
   ],
   "source": [
    "#assuming 30 fps \n",
    "fps = 30.0\n",
    "\n",
    "print(start_frame)\n",
    "\n",
    "# each are specified in seconds\n",
    "start_time = float(start_frame) / float(fps)\n",
    "end_time = float(end_frame) / float(fps)\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(start_time)\n",
    "print(end_time)\n",
    "print(duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut videos in 10s samples\n",
    "subprocess.call([\"mkdir\", proc_dir + \"/tmp\"])\n",
    "subprocess.call([ffmpeg, \"-i\", proc_dir + \"/proc/video_process.mp4\", \"-ss\", str((start_time)), \"-to\", str((end_time)), proc_dir + \"/tmp/video_process_cropped.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample the vids into 30 fps\n",
    "subprocess.call([ffmpeg, \"-i\", proc_dir + \"/tmp/video_process_cropped.mp4\", \"-r\", \"30\", proc_dir + \"/tmp/thumb%04d.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(proc_dir + \"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .npy from a single clip/activity slice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Processed image 1\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "2\n",
      "Processed image 2\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "3\n",
      "Processed image 3\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "4\n",
      "Processed image 4\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "5\n",
      "Processed image 5\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "6\n",
      "Processed image 6\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "7\n",
      "Processed image 7\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "8\n",
      "Processed image 8\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "9\n",
      "Processed image 9\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "10\n",
      "Processed image 10\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "11\n",
      "Processed image 11\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "12\n",
      "Processed image 12\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "13\n",
      "Processed image 13\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "14\n",
      "Processed image 14\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "15\n",
      "Processed image 15\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "16\n",
      "Processed image 16\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "17\n",
      "Processed image 17\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "18\n",
      "Processed image 18\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "19\n",
      "Processed image 19\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "20\n",
      "Processed image 20\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "21\n",
      "Processed image 21\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "22\n",
      "Processed image 22\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "23\n",
      "Processed image 23\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "24\n",
      "Processed image 24\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "25\n",
      "Processed image 25\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "26\n",
      "Processed image 26\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "27\n",
      "Processed image 27\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "28\n",
      "Processed image 28\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "29\n",
      "Processed image 29\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "30\n",
      "Processed image 30\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "31\n",
      "Processed image 31\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "32\n",
      "Processed image 32\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "33\n",
      "Processed image 33\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "34\n",
      "Processed image 34\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "35\n",
      "Processed image 35\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "36\n",
      "Processed image 36\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "37\n",
      "Processed image 37\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "38\n",
      "Processed image 38\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "39\n",
      "Processed image 39\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "40\n",
      "Processed image 40\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "41\n",
      "Processed image 41\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "42\n",
      "Processed image 42\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "43\n",
      "Processed image 43\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "44\n",
      "Processed image 44\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "45\n",
      "Processed image 45\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n",
      "46\n",
      "Processed image 46\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 116 164\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "destination_dir = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir\"\n",
    "\n",
    "start = 1\n",
    "end = int(fps * duration)\n",
    "\n",
    "# loop through all images, 30 fps for DURATION seconds\n",
    "for i in range(start, end-1):\n",
    "    image_str = proc_dir + \"/tmp/thumb\" + ('%04d' % i) + \".jpg\"\n",
    "    image = cv2.imread(image_str, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # Convert to Greyscale\n",
    "    if (i == 1):\n",
    "        prev_image = image\n",
    "\n",
    "    print(i)\n",
    "    # pretty sure our images are already gray, so not sure if we need these pre-processing steps:\n",
    "    gray_image_prev = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Run optical flow: \n",
    "    '''\n",
    "    dtvl1 = cv2.createOptFlow_DualTVL1()\n",
    "    image_flowDTVL1 = dtvl1.calc(gray_image_prev, gray_image, None)    \n",
    "    \n",
    "    # Truncate Pixels between [-20, 20]\n",
    "    image_flow_truncated = np.clip(image_flowDTVL1, -20, 20)\n",
    "\n",
    "    # Normalize image into [-1, 1]\n",
    "    norm_image_flow = cv2.normalize(image_flow_truncated, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # Crop 224x224 samples\n",
    "\n",
    "    # reshape\n",
    "    norm_image_flow_r = norm_image_flow.reshape(1, 224, 224, 2)\n",
    "    '''\n",
    "    \n",
    "    norm_image_flow_r = gray_image\n",
    "\n",
    "    # Add to Flow numpy\n",
    "    if (i == 1):\n",
    "        flow_video = norm_image_flow_r\n",
    "    else:\n",
    "        flow_video = np.concatenate((flow_video, norm_image_flow_r), axis=0)\n",
    "\n",
    "    prev_image = image\n",
    "\n",
    "    print(\"Processed image \" + str(i))\n",
    "    \n",
    "    #flow_video_r = flow_video.reshape(start, end, 224, 224, 2)\n",
    "    \n",
    "    # when done, copy .npy files for one 10s video clip, RGB and Flow\n",
    "    subprocess.call([\"mkdir\", destination_dir + \"/video_flow/\"])\n",
    "    destination_flow = destination_dir + \"/video_flow/\" + video_filename[4:] + \"_\" + str(start_frame) + str(end_frame) + \".npy\"\n",
    "    np.save(destination_flow, flow_video)\n",
    "    print(\"Processed video \" + video_filename + \" \" + str(start_frame) + \" \" + str(end_frame))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: \n",
    "# 1. Add label\n",
    "# 2. Loop through all activity slices in .csv file\n",
    "# 3. Optical FLOW and RGB Flow code? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //TO DO: (not implemented yet)\n",
    "## Now do same as above, but loop through every row in the .csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range (0, len(annotations_df)):\n",
    "    video_filename = str(annotations_df[\"file_id\"][row]) + \".mp4\"        # Get video filename for each row\n",
    "\n",
    "    # Extract the frames using start_frame and end_frame\n",
    "    start_frame = annotations_df[\"frame_start\"][row]\n",
    "    end_frame = annotations_df[\"frame_end\"][row]\n",
    "\n",
    "    activity = annotations_df[\"activity\"][row]\n",
    "    label = label_encoding(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
