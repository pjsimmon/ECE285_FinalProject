{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to pre-process the .mp4 videos from the Drive&Act Dataset by extracting frames into .npy files with their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a one-hot-encoding helper function here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to modify input \"data_set\"\n",
    "def label_encoding(activity):\n",
    "    if activity == 'sitting_still':\n",
    "        activity = 0\n",
    "    elif activity == 'standing_by_the_door':\n",
    "        activity = 1\n",
    "    elif activity == 'entering_car':\n",
    "        activity = 2\n",
    "    elif activity == 'closing_door_outside':\n",
    "        activity = 3\n",
    "    elif activity == 'closing_door_inside':\n",
    "        activity = 4\n",
    "    elif activity == 'opening_laptop':\n",
    "        activity = 5\n",
    "    elif activity == 'opening_door_inside':\n",
    "        activity = 6\n",
    "    elif activity == 'fetching_an_object':\n",
    "        activity = 7\n",
    "    elif activity == 'pressing_automation_button':\n",
    "        activity = 8\n",
    "    elif activity == 'fastening_seat_belt':\n",
    "        activity = 9\n",
    "    elif activity == 'using_multimedia_display':\n",
    "        activity = 10\n",
    "    elif activity == 'closing_laptop':\n",
    "        activity = 11\n",
    "    elif activity == 'placing_an_object':\n",
    "        activity = 12\n",
    "    elif activity == 'interacting_with_phone':\n",
    "        activity = 13\n",
    "    elif activity == 'drinking':\n",
    "        activity = 14\n",
    "    elif activity == 'opening_bottle':\n",
    "        activity = 15\n",
    "    elif activity == 'eating':\n",
    "        activity = 16\n",
    "    elif activity == 'preparing_food':\n",
    "        activity = 17\n",
    "    elif activity == 'looking_back_left_shoulder':\n",
    "        activity = 18\n",
    "    elif activity == 'reading_magazine':\n",
    "        activity = 19\n",
    "    elif activity == 'talking_on_phone':\n",
    "        activity = 20\n",
    "    elif activity == 'looking_or_moving_around (e.g. searching)':\n",
    "        activity = 21\n",
    "    elif activity == 'closing_bottle':\n",
    "        activity = 22\n",
    "    elif activity == 'putting_on_jacket':\n",
    "        activity = 23\n",
    "    elif activity == 'exiting_car':\n",
    "        activity = 24\n",
    "    elif activity == 'opening_door_outside':\n",
    "        activity = 25\n",
    "    elif activity == 'writing':\n",
    "        activity = 26\n",
    "    elif activity == 'working_on_laptop':\n",
    "        activity = 27\n",
    "    elif activity == 'putting_on_sunglasses':\n",
    "        activity = 28\n",
    "    elif activity == 'taking_off_sunglasses':\n",
    "        activity = 29\n",
    "    elif activity == 'opening_backpack':\n",
    "        activity = 30\n",
    "    elif activity == 'taking_laptop_from_backpack':\n",
    "        activity = 31\n",
    "    elif activity == 'reading_newspaper':\n",
    "        activity = 32\n",
    "    elif activity == 'taking_off_jacket':\n",
    "        activity = 33\n",
    "    elif activity == 'unfastening_seat_belt':\n",
    "        activity = 34\n",
    "    elif activity == 'putting_laptop_into_backpack':\n",
    "        activity = 35\n",
    "    else:\n",
    "        print(activity)\n",
    "\n",
    "    return int(activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test getting frames from single video for single row (activity slice) from the provided .csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/activities_3s/kinect_ir/\"\n",
    "filename = \"midlevel.chunks_90.split_0.train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>activity</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>164</td>\n",
       "      <td>closing_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>260</td>\n",
       "      <td>opening_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>313</td>\n",
       "      <td>entering_car</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>5</td>\n",
       "      <td>313</td>\n",
       "      <td>348</td>\n",
       "      <td>closing_door_inside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_ir</td>\n",
       "      <td>6</td>\n",
       "      <td>348</td>\n",
       "      <td>439</td>\n",
       "      <td>fastening_seat_belt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id                                  file_id  annotation_id  \\\n",
       "0               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              1   \n",
       "1               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              3   \n",
       "2               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              4   \n",
       "3               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              5   \n",
       "4               1  vp1/run1b_2018-05-29-14-02-47.kinect_ir              6   \n",
       "\n",
       "   frame_start  frame_end              activity  chunk_id  \n",
       "0          116        164  closing_door_outside         0  \n",
       "1          204        260  opening_door_outside         0  \n",
       "2          260        313          entering_car         0  \n",
       "3          313        348   closing_door_inside         0  \n",
       "4          348        439   fastening_seat_belt         0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = pd.read_csv(path + filename)\n",
    "print(len(annotations_df))\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir/\"\n",
    "os.path.exists(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 204 260\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n",
      "Processed video vp1/run1b_2018-05-29-14-02-47.kinect_ir.mp4 260 313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-42309b7e3960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mkdir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/video_flow/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdestination_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/video_flow/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvideo_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 536\u001b[0;31m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    537\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "\n",
    "root_dir = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir\"\n",
    "\n",
    "for row in range(0, len(annotations_df)):\n",
    "    #  Get video filename for each row\n",
    "    video_filename = str(annotations_df[\"file_id\"][row]) + \".mp4\"        \n",
    "\n",
    "    # Extract the frames using start_frame and end_frame\n",
    "    start_frame = annotations_df[\"frame_start\"][row]\n",
    "    end_frame = annotations_df[\"frame_end\"][row]\n",
    "\n",
    "    activity = annotations_df[\"activity\"][row]\n",
    "    label = label_encoding(activity)\n",
    "    \n",
    "    video_path = root_dir + \"/\" + video_filename\n",
    "    \n",
    "    # Remove all files in prev. \"proc\" directory and recreate for this activity slice\n",
    "    subprocess.call([\"rm\", \"-rf\", root_dir + \"/proc\"])\n",
    "    subprocess.call([\"mkdir\", root_dir + \"/proc\"])\n",
    "       \n",
    "    ffmpeg = \"/Users/jasminesimmons/Downloads/ffmpeg\"\n",
    "    subprocess.call([ffmpeg, \"-i\", video_path, \"-r\", \"30\", \"-s\", \"224x224\", \"-aspect\", \"4:3\", \"proc/video_process.mp4\"])\n",
    "\n",
    "    #assuming 30 fps \n",
    "    fps = 30.0\n",
    "\n",
    "    # each are specified in seconds\n",
    "    start_time = float(start_frame) / float(fps)\n",
    "    end_time = float(end_frame) / float(fps)\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # cut videos into activty chunk samples\n",
    "    subprocess.call([\"mkdir\", root_dir + \"/tmp\"])\n",
    "    subprocess.call([ffmpeg, \"-i\", root_dir + \"/proc/video_process.mp4\", \"-ss\", str((start_time)), \"-to\", str((end_time)), root_dir + \"/tmp/video_process_cropped.mp4\"])\n",
    "    \n",
    "    # sample the vids into 30 fps\n",
    "    subprocess.call([ffmpeg, \"-i\", root_dir + \"/tmp/video_process_cropped.mp4\", \"-r\", \"30\", root_dir + \"/tmp/thumb%04d.jpg\"])\n",
    "    \n",
    "    start = 1\n",
    "    end = int(fps * duration)\n",
    "\n",
    "    # loop through all images, 30 fps for DURATION seconds\n",
    "    for i in range(start, end):\n",
    "        \n",
    "        image_str = root_dir + \"/tmp/thumb\" + ('%04d' % i) + \".jpg\"\n",
    "        \n",
    "        # Check to make sure that the file exists: \n",
    "        if os.path.exists(root_dir + \"/tmp/thumb\" + ('%04d' % i) + \".jpg\"):\n",
    "            gray_image = imageio.imread(image_str)\n",
    "\n",
    "            # Convert to Greyscale\n",
    "            # if (i == 1):\n",
    "            #    prev_image = image\n",
    "\n",
    "            # pretty sure our images are already gray, so not sure if we need these pre-processing steps:\n",
    "            #gray_image_prev = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "            #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Run optical flow: \n",
    "            '''\n",
    "            dtvl1 = cv2.createOptFlow_DualTVL1()\n",
    "            image_flowDTVL1 = dtvl1.calc(gray_image_prev, gray_image, None)    \n",
    "\n",
    "            # Truncate Pixels between [-20, 20]\n",
    "            image_flow_truncated = np.clip(image_flowDTVL1, -20, 20)\n",
    "\n",
    "            # Normalize image into [-1, 1]\n",
    "            norm_image_flow = cv2.normalize(image_flow_truncated, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "            # Crop 224x224 samples\n",
    "\n",
    "            # reshape\n",
    "            norm_image_flow_r = norm_image_flow.reshape(1, 224, 224, 2)\n",
    "            '''\n",
    "\n",
    "            norm_image_flow_r = gray_image\n",
    "\n",
    "            # Add to Flow numpy\n",
    "            if (i == 1):\n",
    "                flow_video = norm_image_flow_r\n",
    "            else:\n",
    "                flow_video = np.concatenate((flow_video, norm_image_flow_r), axis=0)\n",
    "\n",
    "            prev_image = image\n",
    "\n",
    "            # print(\"Processed image \" + str(i))\n",
    "\n",
    "    #flow_video_r = flow_video.reshape(start, end, 224, 224, 2)\n",
    "\n",
    "    # when done, copy .npy files for one 10s video clip, RGB and Flow\n",
    "    subprocess.call([\"mkdir\", root_dir + \"/video_flow/\"])\n",
    "    destination_flow = root_dir + \"/video_flow/\" + video_filename[4:] + \"_\" + str(start_frame) + str(end_frame) + \".npy\"\n",
    "    np.save(destination_flow, flow_video)\n",
    "\n",
    "    with open(root_dir + '/video_flow/' + filename[:-3] + 'txt', \"w\") as txt_file: \n",
    "        txt_file.write(video_filename[4:] + \"_\" + str(start_frame) + str(end_frame) + \".npy\" + \" \" + str(label) + \"\\n\")\n",
    "\n",
    "    if row == 1 or row == 2: \n",
    "        print(\"Processed video \" + video_filename + \" \" + str(start_frame) + \" \" + str(end_frame))\n",
    "\n",
    "print(\"Done processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .npy from a single clip/activity slice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: \n",
    "# 1. Add label (done)\n",
    "# 2. Loop through all activity slices in .csv file\n",
    "# 3. Optical FLOW and RGB Flow code? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_irvideo_flow/midlevel.chunks_90.split_0.train.txt\n"
     ]
    }
   ],
   "source": [
    "# Open a text file and record the .npy with the activity one-hot-encoding: \n",
    "# Place the file in: kinect_ir/video_flow/training.txt\n",
    "txt_path = 'Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir/video_flow/' + filename[:-3] + 'txt'\n",
    "print(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir\"\n",
    "os.path.exists(root_dir + '/video_flow/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasminesimmons/Grad_School/Spring_Qtr_2020/ECE285/Code_Final_Project/ECE285_Final_Dataset/kinect_ir/video_flow/midlevel.chunks_90.split_0.train.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(root_dir + '/video_flow/' + filename[:-3] + 'txt')\n",
    "with open(root_dir + '/video_flow/' + filename[:-3] + 'txt', \"w\") as txt_file: \n",
    "    txt_file.write(video_filename[4:] + \"_\" + str(start_frame) + str(end_frame) + \".npy\" + \" \" + str(label) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //TO DO: (not implemented yet)\n",
    "## Now do same as above, but loop through every row in the .csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
